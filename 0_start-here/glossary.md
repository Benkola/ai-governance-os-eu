# Glossary

## EU AI Act terms
- **Provider:** entity that develops and places an AI system on the market / puts it into service
- **Deployer:** entity using an AI system under its authority
- **High-risk AI system:** AI system in specified high-impact areas or as a safety component; triggers specific obligations
- **GPAI (General-purpose AI):** AI model/system with broad capability used across many tasks

## Governance terms
- **Control:** a policy/process/technical measure that reduces a defined risk
- **Evidence:** an artefact or record that demonstrates a control exists and is operating
- **Risk acceptance criteria:** conditions under which leadership agrees risk is acceptable
- **Human oversight:** defined human responsibilities and interventions to prevent/mitigate harms
- **Audit trail:** records proving what was decided, by whom, with what evidence, when

## ML/GenAI terms
- **Model:** ML model/LLM component
- **System:** model + data + UI + workflows + oversight + monitoring
- **Drift:** changes in data/model behaviour over time impacting performance/safety
- **Evaluation:** assessing performance/safety (offline tests, online metrics, human review)
- **Red teaming:** adversarial testing to identify misuse/abuse, harmful outputs, failures
- **Prompt injection:** attempts to override system instructions or access restricted data
- **Hallucination:** generated content that is plausible but incorrect/ungrounded
- **Data leakage:** sensitive information unintentionally exposed through model outputs/logs
- **Change control:** controlled process to deploy, update, and rollback AI systems safely

## Operational terms
- **Go/No-Go:** explicit approval decision to deploy (or not) based on evidence
- **Severity:** classification of incident impact (e.g., Sev1â€“Sev4)
