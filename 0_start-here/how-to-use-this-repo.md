# How to use this repo

## Route A: Approve a use case (fast path)
1) Capture context with the **Intake Form**
2) Identify obligations via **EU AI Act mapping**
3) Populate the **Risk Register** (risks → controls → evidence)
4) Require an **Evidence Pack** before deployment
5) Define **Monitoring + Incident Response**
6) Log approval and schedule periodic review

## Route B: Build governance from scratch (build path)
1) Adopt `1_framework/ai-governance-framework.md`
2) Establish governance forums + cadence (Operating Model)
3) Clarify decision rights (RACI)
4) Baseline maturity + readiness (Maturity Model + Scorecard)
5) Improve by producing evidence and closing gaps

## Route C: Evaluate a vendor (vendor path)
1) Run Supplier Due Diligence
2) Use the Tool Evaluation Rubric
3) Execute a PoC plan with success + risk gates
4) Require monitoring commitments and evidence artefacts

---

## The lifecycle (intake → retire)
- Intake
- Classification/tiering
- Risk assessment
- Build/buy decision
- Evidence gate (documentation + controls)
- Deploy + change control
- Monitor + evaluate
- Incident response
- Retire/decommission

---

## Evidence pack (minimum viable)
An AI system should not be deployed until these exist (minimum):
- Intake record (business purpose + context)
- Risk register entries with mitigations and owners
- Model card + system card (or equivalent documentation)
- Monitoring plan (signals, thresholds, cadence, owners)
- Incident response playbook (severity, escalation, rollback)

---

## Review cadence (minimum viable)
- Monitoring review: monthly (or more often for higher-risk)
- Governance review: quarterly
- Post-incident review: within 5 working days of resolution

---

## Where to start
1) `0_start-here/scope.md`
2) `1_framework/ai-governance-framework.md`
3) (Week 2+) `4_eu-ai-act/eu-ai-act-controls-map.md`
